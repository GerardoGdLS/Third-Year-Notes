{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cfb43af",
   "metadata": {},
   "source": [
    "# Assignment 4: Pipelines and Text Data (60 total marks)\n",
    "### Due: March 21 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f8ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff9ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') #ignoring some deprication warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf05c7e",
   "metadata": {},
   "source": [
    "## Part 1: Pipelines (26 marks)\n",
    "\n",
    "The purpose of this part of the assignment is to practice following the grid-search workflow: \n",
    "- Split data into training and test set\n",
    "- Use the training portion to find the best model using grid search and cross-validation\n",
    "- Retrain the best model\n",
    "- Evaluate the retrained model on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31108625",
   "metadata": {},
   "source": [
    "### 1.1: Load data (4 marks)\n",
    "For this task, we will be using stock data from the Dow Jones Index. This dataset uses information about different stocks to try to predict what the percent change in price will be from week to week.\n",
    "\n",
    "More information on the dataset can be found here: https://archive.ics.uci.edu/dataset/312/dow+jones+index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1e2cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quarter stock       date    open    high     low   close     volume  \\\n",
      "0        1    AA   1/7/2011  $15.82  $16.72  $15.78  $16.42  239655616   \n",
      "1        1    AA  1/14/2011  $16.71  $16.71  $15.64  $15.97  242963398   \n",
      "2        1    AA  1/21/2011  $16.19  $16.38  $15.60  $15.79  138428495   \n",
      "3        1    AA  1/28/2011  $15.87  $16.63  $15.82  $16.13  151379173   \n",
      "4        1    AA   2/4/2011  $16.18  $17.39  $16.18  $17.14  154387761   \n",
      "\n",
      "   percent_change_price  percent_change_volume_over_last_wk  \\\n",
      "0               3.79267                                 NaN   \n",
      "1              -4.42849                            1.380223   \n",
      "2              -2.47066                          -43.024959   \n",
      "3               1.63831                            9.355500   \n",
      "4               5.93325                            1.987452   \n",
      "\n",
      "   previous_weeks_volume next_weeks_open next_weeks_close  \\\n",
      "0                    NaN          $16.71           $15.97   \n",
      "1            239655616.0          $16.19           $15.79   \n",
      "2            242963398.0          $15.87           $16.13   \n",
      "3            138428495.0          $16.18           $17.14   \n",
      "4            151379173.0          $17.33           $17.37   \n",
      "\n",
      "   percent_change_next_weeks_price  days_to_next_dividend  \\\n",
      "0                        -4.428490                     26   \n",
      "1                        -2.470660                     19   \n",
      "2                         1.638310                     12   \n",
      "3                         5.933250                      5   \n",
      "4                         0.230814                     97   \n",
      "\n",
      "   percent_return_next_dividend  \n",
      "0                      0.182704  \n",
      "1                      0.187852  \n",
      "2                      0.189994  \n",
      "3                      0.185989  \n",
      "4                      0.175029  \n"
     ]
    }
   ],
   "source": [
    "# TO DO: Load the dataset into a dataframe called stock_data (0.5 marks)\n",
    "stock_data = pd.read_csv('dow_jones_index.data')\n",
    "\n",
    "# TO DO: Inspect the first few columns (0.5 marks)\n",
    "\n",
    "print(stock_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8969a634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quarter                                 int64\n",
      "stock                                  object\n",
      "date                                   object\n",
      "open                                   object\n",
      "high                                   object\n",
      "low                                    object\n",
      "close                                  object\n",
      "volume                                  int64\n",
      "percent_change_price                  float64\n",
      "percent_change_volume_over_last_wk    float64\n",
      "previous_weeks_volume                 float64\n",
      "next_weeks_open                        object\n",
      "next_weeks_close                       object\n",
      "percent_change_next_weeks_price       float64\n",
      "days_to_next_dividend                   int64\n",
      "percent_return_next_dividend          float64\n",
      "dtype: object\n",
      "quarter                                0\n",
      "stock                                  0\n",
      "date                                   0\n",
      "open                                   0\n",
      "high                                   0\n",
      "low                                    0\n",
      "close                                  0\n",
      "volume                                 0\n",
      "percent_change_price                   0\n",
      "percent_change_volume_over_last_wk    30\n",
      "previous_weeks_volume                 30\n",
      "next_weeks_open                        0\n",
      "next_weeks_close                       0\n",
      "percent_change_next_weeks_price        0\n",
      "days_to_next_dividend                  0\n",
      "percent_return_next_dividend           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check the data types of each column and if there are missing values (0.5 marks)\n",
    "\n",
    "print(stock_data.dtypes)\n",
    "print(stock_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17914e32",
   "metadata": {},
   "source": [
    "You should notice in this dataset that there are multiple columns that look numerical, but include a `$` that turns the value into a string (type object). You can use the code below to convert these columns into numerical ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d222ca1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quarter stock       date   open   high    low  close     volume  \\\n",
      "0        1    AA   1/7/2011  15.82  16.72  15.78  16.42  239655616   \n",
      "1        1    AA  1/14/2011  16.71  16.71  15.64  15.97  242963398   \n",
      "2        1    AA  1/21/2011  16.19  16.38  15.60  15.79  138428495   \n",
      "3        1    AA  1/28/2011  15.87  16.63  15.82  16.13  151379173   \n",
      "4        1    AA   2/4/2011  16.18  17.39  16.18  17.14  154387761   \n",
      "\n",
      "   percent_change_price  percent_change_volume_over_last_wk  \\\n",
      "0               3.79267                                 NaN   \n",
      "1              -4.42849                            1.380223   \n",
      "2              -2.47066                          -43.024959   \n",
      "3               1.63831                            9.355500   \n",
      "4               5.93325                            1.987452   \n",
      "\n",
      "   previous_weeks_volume  next_weeks_open  next_weeks_close  \\\n",
      "0                    NaN            16.71             15.97   \n",
      "1            239655616.0            16.19             15.79   \n",
      "2            242963398.0            15.87             16.13   \n",
      "3            138428495.0            16.18             17.14   \n",
      "4            151379173.0            17.33             17.37   \n",
      "\n",
      "   percent_change_next_weeks_price  days_to_next_dividend  \\\n",
      "0                        -4.428490                     26   \n",
      "1                        -2.470660                     19   \n",
      "2                         1.638310                     12   \n",
      "3                         5.933250                      5   \n",
      "4                         0.230814                     97   \n",
      "\n",
      "   percent_return_next_dividend  \n",
      "0                      0.182704  \n",
      "1                      0.187852  \n",
      "2                      0.189994  \n",
      "3                      0.185989  \n",
      "4                      0.175029  \n"
     ]
    }
   ],
   "source": [
    "# TO DO: Fill-in which columns need the $ to be removed (1 mark)\n",
    "columns = ['open', 'high', 'low', 'close', 'next_weeks_open', 'next_weeks_close']   \n",
    "\n",
    "# Code to remove $ - DO NOT CHANGE\n",
    "stock_data[columns] = stock_data[columns].replace('[\\$]', '', regex=True).astype(float)\n",
    "\n",
    "# TO DO: Inspect first few rows to make sure it worked (0.5 marks)\n",
    "print(stock_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad28a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quarter                                 int64\n",
      "stock                                  object\n",
      "date                                   object\n",
      "open                                  float64\n",
      "high                                  float64\n",
      "low                                   float64\n",
      "close                                 float64\n",
      "volume                                  int64\n",
      "percent_change_price                  float64\n",
      "percent_change_volume_over_last_wk    float64\n",
      "previous_weeks_volume                 float64\n",
      "next_weeks_open                       float64\n",
      "next_weeks_close                      float64\n",
      "percent_change_next_weeks_price       float64\n",
      "days_to_next_dividend                   int64\n",
      "percent_return_next_dividend          float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check data type of each column to make sure that the type of the columns selected has changed (0.5 marks)\n",
    "print(stock_data.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dac4013",
   "metadata": {},
   "source": [
    "The first thing we need to do is deal with missing values. Looking at the dataset, there are two columns with 30 missing values. For this case, we will drop these rows instead of filling them in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd2350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Drop rows with missing data (0.5 marks)\n",
    "\n",
    "stock_data = stock_data.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b10d14a",
   "metadata": {},
   "source": [
    "### 1.2: Pre-processing (4 marks)\n",
    "\n",
    "In this dataset, we have columns with:\n",
    "- Categorical values\n",
    "- Numerical values\n",
    "\n",
    "We need to create a column transformer that will use the proper preprocessing methods on each type of column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e30a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create Column Transformer using an encoder and StandardScaler (1 mark)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [(\"scaling\", StandardScaler(), ['quarter', 'open', 'high', 'low', 'close', 'volume', 'next_weeks_open', 'next_weeks_close']),\n",
    "     (\"onehot\", OneHotEncoder(sparse_output=False), ['stock'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f08685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Initialize your pipeline with your column transformer and the Ridge Regression model (1 mark)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', ct), ('classifier', Ridge())          \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Separate data into feature matrix and target vector (1 mark)\n",
    "\n",
    "X = stock_data.drop(columns=['percent_change_next_weeks_price'])\n",
    "y = stock_data['percent_change_next_weeks_price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d815ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Split data into training and testing sets (use random_state=0 and 10% of the data for testing) (0.5 marks)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e626fe",
   "metadata": {},
   "source": [
    "Create another column transformer that does not implement scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39312544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create a new column transformer that only performs encoding (0.5 marks)\n",
    "\n",
    "ct_encoding = ColumnTransformer(\n",
    "    [(\"onehot\", OneHotEncoder(), ['stock'])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd751b7a",
   "metadata": {},
   "source": [
    "### 1.3: Grid Search (4 marks)\n",
    "\n",
    "For the grid search, we want to compare the performance of the Random Forest model to a Ridge Regression model with the two different column transformers. Think about if we need to use scaling for both models. Select parameter values to test that make sense for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee11c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create parameter grid and initialize grid object (3 marks)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = [\n",
    "    {'classifier': [Ridge()], 'classifier__alpha': [0.1, 1.0, 10.0]},\n",
    "    {'classifier': [RandomForestRegressor()], 'classifier__n_estimators': [50, 100, 200], 'classifier__max_depth': [None, 10, 20]}\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b4e4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;scaling&#x27;,\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         [&#x27;quarter&#x27;,\n",
       "                                                                          &#x27;open&#x27;,\n",
       "                                                                          &#x27;high&#x27;,\n",
       "                                                                          &#x27;low&#x27;,\n",
       "                                                                          &#x27;close&#x27;,\n",
       "                                                                          &#x27;volume&#x27;,\n",
       "                                                                          &#x27;next_weeks_open&#x27;,\n",
       "                                                                          &#x27;next_weeks_close&#x27;]),\n",
       "                                                                        (&#x27;onehot&#x27;,\n",
       "                                                                         OneHotEncoder(sparse_output=False),\n",
       "                                                                         [&#x27;stock&#x27;])])),\n",
       "                                       (&#x27;classifier&#x27;, Ridge())]),\n",
       "             param_grid=[{&#x27;classifier&#x27;: [Ridge()],\n",
       "                          &#x27;classifier__alpha&#x27;: [0.1, 1.0, 10.0]},\n",
       "                         {&#x27;classifier&#x27;: [RandomForestRegressor()],\n",
       "                          &#x27;classifier__max_depth&#x27;: [None, 10, 20],\n",
       "                          &#x27;classifier__n_estimators&#x27;: [50, 100, 200]}],\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;scaling&#x27;,\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         [&#x27;quarter&#x27;,\n",
       "                                                                          &#x27;open&#x27;,\n",
       "                                                                          &#x27;high&#x27;,\n",
       "                                                                          &#x27;low&#x27;,\n",
       "                                                                          &#x27;close&#x27;,\n",
       "                                                                          &#x27;volume&#x27;,\n",
       "                                                                          &#x27;next_weeks_open&#x27;,\n",
       "                                                                          &#x27;next_weeks_close&#x27;]),\n",
       "                                                                        (&#x27;onehot&#x27;,\n",
       "                                                                         OneHotEncoder(sparse_output=False),\n",
       "                                                                         [&#x27;stock&#x27;])])),\n",
       "                                       (&#x27;classifier&#x27;, Ridge())]),\n",
       "             param_grid=[{&#x27;classifier&#x27;: [Ridge()],\n",
       "                          &#x27;classifier__alpha&#x27;: [0.1, 1.0, 10.0]},\n",
       "                         {&#x27;classifier&#x27;: [RandomForestRegressor()],\n",
       "                          &#x27;classifier__max_depth&#x27;: [None, 10, 20],\n",
       "                          &#x27;classifier__n_estimators&#x27;: [50, 100, 200]}],\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;scaling&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;quarter&#x27;, &#x27;open&#x27;, &#x27;high&#x27;,\n",
       "                                                   &#x27;low&#x27;, &#x27;close&#x27;, &#x27;volume&#x27;,\n",
       "                                                   &#x27;next_weeks_open&#x27;,\n",
       "                                                   &#x27;next_weeks_close&#x27;]),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  [&#x27;stock&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, Ridge(alpha=0.1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocessor: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;scaling&#x27;, StandardScaler(),\n",
       "                                 [&#x27;quarter&#x27;, &#x27;open&#x27;, &#x27;high&#x27;, &#x27;low&#x27;, &#x27;close&#x27;,\n",
       "                                  &#x27;volume&#x27;, &#x27;next_weeks_open&#x27;,\n",
       "                                  &#x27;next_weeks_close&#x27;]),\n",
       "                                (&#x27;onehot&#x27;, OneHotEncoder(sparse_output=False),\n",
       "                                 [&#x27;stock&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>scaling</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;quarter&#x27;, &#x27;open&#x27;, &#x27;high&#x27;, &#x27;low&#x27;, &#x27;close&#x27;, &#x27;volume&#x27;, &#x27;next_weeks_open&#x27;, &#x27;next_weeks_close&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>onehot</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;stock&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(sparse_output=False)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Ridge</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.Ridge.html\">?<span>Documentation for Ridge</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>Ridge(alpha=0.1)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('scaling',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         ['quarter',\n",
       "                                                                          'open',\n",
       "                                                                          'high',\n",
       "                                                                          'low',\n",
       "                                                                          'close',\n",
       "                                                                          'volume',\n",
       "                                                                          'next_weeks_open',\n",
       "                                                                          'next_weeks_close']),\n",
       "                                                                        ('onehot',\n",
       "                                                                         OneHotEncoder(sparse_output=False),\n",
       "                                                                         ['stock'])])),\n",
       "                                       ('classifier', Ridge())]),\n",
       "             param_grid=[{'classifier': [Ridge()],\n",
       "                          'classifier__alpha': [0.1, 1.0, 10.0]},\n",
       "                         {'classifier': [RandomForestRegressor()],\n",
       "                          'classifier__max_depth': [None, 10, 20],\n",
       "                          'classifier__n_estimators': [50, 100, 200]}],\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Fit grid object to training data (1 mark)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec58f86",
   "metadata": {},
   "source": [
    "### 1.4: Visualize Results (2 marks)\n",
    "\n",
    "The final step is to print out the results from the grid search. You will need to print out the following items:\n",
    "- Best parameters\n",
    "- Best cross-validation train score \n",
    "- Best cross-validation test score\n",
    "- Test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acc228e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier': Ridge(), 'classifier__alpha': 0.1}\n",
      "Best cross-validation train score: 2.343672115286629\n",
      "Best cross-validation test score: 2.343672115286629\n",
      "Test set accuracy (MSE): 2.9823291966135437\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print the results from the grid search (2 marks)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best cross-validation train score:\", -grid.best_score_)\n",
    "print(\"Best cross-validation test score:\", -grid.cv_results_['mean_test_score'][grid.best_index_])\n",
    "test_score = grid.score(X_test, y_test)\n",
    "print(\"Test set accuracy (MSE):\", -test_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7324c9",
   "metadata": {},
   "source": [
    "### Questions (8 marks)\n",
    "\n",
    "1. Which models did you use scaling for? Why?\n",
    "1. Which model and what parameters produced the best results?\n",
    "1. Was this model a good fit? Why or why not?\n",
    "1. Is there anything else we could do to try to improve model performance? Provide two ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35ff2b",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "\n",
    "1. I used scaling for the Ridge Regression model because it is sensitive to the scale of the input features and this was decided since Random Forest is not sensitive to the scale of the input features since it is based on decision trees.\n",
    "\n",
    "2. The model that produced the best results was the Ridge Regression model with prarameters of "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd7f37f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee2f4ee",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE - BE SPECIFIC*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1446bc2",
   "metadata": {},
   "source": [
    "## Part 2: Text Data (32 marks)\n",
    "\n",
    "The purpose of this part of the assignment is to practice working with text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864c0a90",
   "metadata": {},
   "source": [
    "### 2.1: Load data (1 mark)\n",
    "For this task, we will be using the hobbies dataset from the yellowbrick library. More information on the dataset can be found here: https://www.scikit-yb.org/en/latest/api/datasets/hobbies.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93604d5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Corpus' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[213], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myellowbrick\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_hobbies\n\u001b[1;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m load_hobbies()\n\u001b[0;32m----> 7\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Corpus' object has no attribute 'info'"
     ]
    }
   ],
   "source": [
    "# TO DO: Load the dataset (1 mark)\n",
    "\n",
    "from yellowbrick.datasets import load_hobbies\n",
    "\n",
    "data = load_hobbies()\n",
    "\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f72f48e",
   "metadata": {},
   "source": [
    "### 2.2 Pre-processing (3 marks)\n",
    "\n",
    "We will need to transform the data from strings to numeric. First, we will transform the data using `CountVectorizer(min_df=5)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1deaaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create CountVectorizer object (0.5 marks)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(min_df=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cbc92d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[197], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TO DO: Fit vectorizer to data (0.5 marks)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mvect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1327\u001b[0m, in \u001b[0;36mCountVectorizer.fit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, raw_documents, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Learn a vocabulary dictionary of all tokens in the raw documents.\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \n\u001b[1;32m   1314\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;124;03m        Fitted vectorizer.\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1327\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1376\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1368\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1369\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1370\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1371\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1372\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1373\u001b[0m             )\n\u001b[1;32m   1374\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1376\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1379\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1282\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[0;32m-> 1282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1283\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1284\u001b[0m         )\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "# TO DO: Fit vectorizer to data (0.5 marks)\n",
    "\n",
    "vect.fit(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c812613c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'vocabulary_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TO DO: What is the length of the vocabulary? (0.5 marks)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m vocab_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mvect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocabulary_\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'vocabulary_'"
     ]
    }
   ],
   "source": [
    "# TO DO: What is the length of the vocabulary? (0.5 marks)\n",
    "\n",
    "vocab_length = len(vect.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696f51c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TO DO: Transform the data (0.5 marks)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1418\u001b[0m, in \u001b[0;36mCountVectorizer.transform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(raw_documents, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1416\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterable over raw text documents expected, string object received.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1417\u001b[0m     )\n\u001b[0;32m-> 1418\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;66;03m# use the same matrix-building strategy as fit_transform\u001b[39;00m\n\u001b[1;32m   1421\u001b[0m _, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, fixed_vocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:501\u001b[0m, in \u001b[0;36m_VectorizerMixin._check_vocabulary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_vocabulary()\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_:\n\u001b[0;32m--> 501\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVocabulary not fitted or provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocabulary_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVocabulary is empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "# TO DO: Transform the data (0.5 marks)\n",
    "\n",
    "X = vect.transform(data.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bedc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of transformed data: (720, 15)\n"
     ]
    }
   ],
   "source": [
    "# TO DO: What is the shape of the transformed data? (0.5 marks)\n",
    "\n",
    "print(\"Shape of transformed data:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e03a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [720, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[157], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TO DO: Split data into training and testing sets (use random_state=0 and 10% of the data for testing) (0.5 marks)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> 5\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2848\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2848\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2850\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2851\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2852\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2853\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:532\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \n\u001b[1;32m    504\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    531\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 532\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    478\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [720, 0]"
     ]
    }
   ],
   "source": [
    "# TO DO: Split data into training and testing sets (use random_state=0 and 10% of the data for testing) (0.5 marks)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, data.target, random_state=0, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d11f4e",
   "metadata": {},
   "source": [
    "### 2.3: Grid Search (5 marks)\n",
    "\n",
    "For the grid search, we want to compare the performance of Logistic Regression for different values of C. Initialize the parameter grid with parameter values that make sense for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137d6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create parameter grid and initialize grid object (2 marks)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=287)\n",
    "\n",
    "param_grid = {'C': [0.01, 0.1, 1.0, 10.0]}\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=500), param_grid=param_grid, cv=cv, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80113917",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[160], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TO DO: Fit grid object to training data (1 mark)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:982\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[1;32m    970\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    971\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m         clone(base_estimator),\n\u001b[1;32m    973\u001b[0m         X,\n\u001b[1;32m    974\u001b[0m         y,\n\u001b[1;32m    975\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    976\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    977\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    978\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    979\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    980\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    981\u001b[0m     )\n\u001b[0;32m--> 982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m )\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_split.py:411\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    405\u001b[0m         (\n\u001b[1;32m    406\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    407\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[1;32m    409\u001b[0m     )\n\u001b[0;32m--> 411\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_split.py:142\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    140\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m    141\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(_num_samples(X))\n\u001b[0;32m--> 142\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_test_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_not\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_split.py:838\u001b[0m, in \u001b[0;36mStratifiedKFold._iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_iter_test_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 838\u001b[0m     test_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_test_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits):\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m test_folds \u001b[38;5;241m==\u001b[39m i\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_split.py:781\u001b[0m, in \u001b[0;36mStratifiedKFold._make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    779\u001b[0m allowed_target_types \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_of_target_y \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_target_types:\n\u001b[0;32m--> 781\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    782\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported target types are: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    783\u001b[0m             allowed_target_types, type_of_target_y\n\u001b[1;32m    784\u001b[0m         )\n\u001b[1;32m    785\u001b[0m     )\n\u001b[1;32m    787\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y)\n\u001b[1;32m    789\u001b[0m _, y_idx, y_inv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y, return_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead."
     ]
    }
   ],
   "source": [
    "# TO DO: Fit grid object to training data (1 mark)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3995afa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[161], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TO DO: Print the results from the grid search (2 marks)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest params:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_params_\u001b[49m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest cross-validation train score: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(grid\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_train_score\u001b[39m\u001b[38;5;124m'\u001b[39m][grid\u001b[38;5;241m.\u001b[39mbest_index_]))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest cross-validation score: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(grid\u001b[38;5;241m.\u001b[39mbest_score_))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "# TO DO: Print the results from the grid search (2 marks)\n",
    "\n",
    "print(\"Best params:\\\\n{}\\\\n\".format(grid.best_params_))\n",
    "print(\"Best cross-validation train score: {:.2f}\".format(grid.cv_results_['mean_train_score'][grid.best_index_]))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Test-set score: {:.2f}\".format(grid.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31294d74",
   "metadata": {},
   "source": [
    "### 2.4: Additional Model Comparisons (9 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ca2da7",
   "metadata": {},
   "source": [
    "### 2.4.1: Naive Bayes (3 marks)\n",
    "We would like to compare the performance of Logistic Regression with one of the Naive Bayes models. Pick the Naive Bayes model that you think would best suit text data and implement below. Since we are not adjusting hyperparameters, we can use `cross_validate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b6ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Implement Naive Bayes model with cross-validate (2 marks)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "nb = MultinomialNB()\n",
    "scores = cross_val_score(nb, X_train, y_train, cv=cv)\n",
    "\n",
    "\n",
    "# TO DO: Print training and validation accuracies\n",
    "print(\"Training accuracy: {:.2f}\".format(scores.mean()))\n",
    "print(\"Validation accuracy: {:.2f}\".format(scores.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d505f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Calculate and print test accuracy (1 mark)\n",
    "nb.fit(X_train, y_train)\n",
    "test_accuracy = nb.score(X_test, y_test)\n",
    "print(\"Test accuracy: {:.2f}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ed1f4",
   "metadata": {},
   "source": [
    "### 2.4.2 Tf-idf (6 marks)\n",
    "\n",
    "To try to improve the results, we can try using Tf-idf to tranform the text data based on the importance of each feature. We will need to use a pipeline and the original data for this section. Use `TfidfVectorizer(min_df=5)` and compare the results for both Logistic Regression and your selected Naive Bayes model. Use the Logistic Regression parameters from the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ddef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Split the data into training and testing sets (same values as previous section) (1 mark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b7a2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Implement Pipeline with Tf-idf vectorizer and both Logistic Regression and your selected Naive Bayes model (3 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea92cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Print the results from the grid search (2 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aee78b",
   "metadata": {},
   "source": [
    "### Questions (10 marks)\n",
    "\n",
    "1. Which Naive Bayes model did you pick? Why?\n",
    "1. Which model and what parameters produced the best results?\n",
    "1. Was this model a good fit? Why or why not?\n",
    "1. Is there anything else we could do to try to improve model performance? Provide two ideas (must be different from Part 1).\n",
    "1. Why did we need to implement a pipeline for Tf-idf and not CountVectorizer? What would happen if we didn't use one for Tf-idf?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323788fa",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40621d7",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdc92f7",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE - BE SPECIFIC*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc65ad6",
   "metadata": {},
   "source": [
    "## Part 3: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9752e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
